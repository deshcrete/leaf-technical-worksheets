{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urPtQG8OZQOy"
   },
   "outputs": [],
   "source": "# Import helper functions - all the implementation details are hidden here!\nfrom helper_interp import (\n    # Model and training\n    create_model, create_optimizer, train_model, \n    load_data, create_dataloaders, plot_training_history,\n    # Visualization\n    visualize_network_architecture, visualize_sample_digits, visualize_prediction,\n    # Activations\n    plot_activations, get_sample_by_digit, get_sample_by_index,\n    # Probes\n    train_probe, visualize_probe_weights, compare_probes_across_layers\n)\nimport matplotlib.pyplot as plt"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture\n",
    "\n",
    "Our MNIST classifier has the following structure:\n",
    "- **Input**: 784 neurons (28x28 flattened image)\n",
    "- **Hidden Layer 1**: 32 neurons + ReLU\n",
    "- **Hidden Layer 2**: 16 neurons + ReLU\n",
    "- **Output**: 10 neurons (one per digit 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the network architecture\nvisualize_network_architecture()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9gWr7eva9ue"
   },
   "outputs": [],
   "source": "# Load the MNIST data\ntrain_imgs, train_lbls, test_imgs, test_lbls = load_data(\n    '/content/sample_data/mnist_train_small.csv', \n    '/content/sample_data/mnist_test.csv'\n)\ntrain_loader, test_loader = create_dataloaders(train_imgs, train_lbls, test_imgs, test_lbls)\n\nprint(f\"Loaded {len(train_imgs)} training samples and {len(test_imgs)} test samples\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Input Digits\n",
    "\n",
    "Let's see what MNIST digits look like - these 28x28 grayscale images are flattened to 784 values before entering the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize sample digits (one of each 0-9)\nvisualize_sample_digits(train_imgs, train_lbls)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJju48Z4brO5",
    "outputId": "6f0898eb-3c43-4f1f-854b-f7c02e7aa1d0"
   },
   "outputs": [],
   "source": "# =============================================================================\n# TRAINING PARAMETERS - You can modify these!\n# =============================================================================\nEPOCHS = 20           # Number of training epochs\nLEARNING_RATE = 0.001  # Learning rate for optimizer\n\n# Create and train the model\nmodel = create_model()\noptimizer = create_optimizer(model, lr=LEARNING_RATE)\nhistory = train_model(model, optimizer, train_loader, test_loader, epochs=EPOCHS)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "id": "Xx6N-YDicPmf",
    "outputId": "c342d57a-6f4e-4c4a-dce6-d9dc4181fbb4"
   },
   "outputs": [],
   "source": "# Plot training progress\nplot_training_history(history)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Output Distributions\n",
    "\n",
    "The network outputs 10 logits which are converted to probabilities via softmax. Let's see how the model's predictions look for different digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CHOOSE A DIGIT TO VISUALIZE - Change this value!\n# =============================================================================\nDIGIT_TO_VIEW = 7  # Try values 0-9\n\n# Get a sample of that digit and show its prediction\nimage, label = get_sample_by_digit(test_imgs, test_lbls, DIGIT_TO_VIEW)\nvisualize_prediction(model, image, label)"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "IFFcScDkc_3U"
   },
   "outputs": [],
   "source": "## Understanding Activations\n\n**What are activations?** As data flows through a neural network, each layer transforms the input and produces an output called an \"activation\". These activations are the intermediate representations the network builds as it processes information.\n\n**Why do they matter?** By examining activations, we can understand:\n- What features each layer has learned to detect\n- How the network transforms raw pixels into abstract concepts\n- Which neurons \"fire\" (have high values) for different inputs\n\nOur network has 5 activation points:\n- **Layer 0**: After first Linear (784 → 32)\n- **Layer 1**: After first ReLU (32 neurons, negative values zeroed)\n- **Layer 2**: After second Linear (32 → 16)\n- **Layer 3**: After second ReLU (16 neurons)\n- **Layer 4**: Output logits (16 → 10)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "an-Tqwnudst1",
    "outputId": "1534206f-7e61-4f74-e27c-545bf9453169"
   },
   "outputs": [],
   "source": "# =============================================================================\n# INTERACTIVE ACTIVATION EXPLORER\n# =============================================================================\n# Choose how to select your input:\n#   - By digit (0-9): Shows activations for a sample of that digit\n#   - By index: Shows activations for a specific sample in the test set\n\n# OPTION 1: Select by digit\nDIGIT_TO_EXPLORE = 5  # Change this! (0-9)\n\nimage, label = get_sample_by_digit(test_imgs, test_lbls, DIGIT_TO_EXPLORE)\nplot_activations(model, image, label)\n\n# OPTION 2: Select by index (uncomment to use)\n# INDEX_TO_EXPLORE = 42  # Change this! (0 to ~10000)\n# image, label = get_sample_by_index(test_imgs, test_lbls, INDEX_TO_EXPLORE)\n# plot_activations(model, image, label)"
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# COMPARE ACTIVATIONS: Two digits side by side\n# =============================================================================\n# See how different digits activate different neurons!\n\nCOMPARE_DIGIT_1 = 1  # A \"simple\" digit\nCOMPARE_DIGIT_2 = 8  # A \"complex\" digit\n\nimg1, lbl1 = get_sample_by_digit(test_imgs, test_lbls, COMPARE_DIGIT_1)\nimg2, lbl2 = get_sample_by_digit(test_imgs, test_lbls, COMPARE_DIGIT_2)\n\nprint(f\"Comparing digit {COMPARE_DIGIT_1} vs digit {COMPARE_DIGIT_2}:\")\nplot_activations(model, img1, lbl1)\nplot_activations(model, img2, lbl2)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Introduction to Probes\n\n**What is a probe?** A probe is a simple classifier (usually linear) trained on the activations of a neural network to detect whether a specific concept is represented in those activations.\n\n**Why use probes?** Probes help us understand:\n- What concepts the network has learned to represent\n- At which layer these concepts emerge\n- Whether the network encodes features we didn't explicitly train it on\n\n**How it works:**\n1. Extract activations from a specific layer for many inputs\n2. Label inputs by the concept we're testing (e.g., \"has a loop\" vs \"no loop\")\n3. Train a simple linear classifier on these activations\n4. If the probe achieves high accuracy, the concept is likely encoded in that layer\n\n**Example concepts to probe:**\n- Digits with loops (0, 6, 8, 9) vs without (1, 2, 3, 4, 5, 7)\n- Even vs odd digits\n- Any digit pair distinction",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# EXPERIMENT 1: Probe for \"digits with loops\"\n# =============================================================================\n# Digits with loops: 0, 6, 8, 9\n# Digits without loops: 1, 2, 3, 4, 5, 7\n#\n# Try changing these groups to test different concepts!\n\nPOSITIVE_DIGITS = [0, 6, 8, 9]  # Digits WITH loops\nNEGATIVE_DIGITS = [1, 2, 3, 4, 5, 7]  # Digits WITHOUT loops\nLAYER_TO_PROBE = 2  # Which layer to probe (0-4)\n\nprobe, accuracy = train_probe(\n    model, train_loader, test_loader,\n    positive_digits=POSITIVE_DIGITS,\n    negative_digits=NEGATIVE_DIGITS,\n    layer_num=LAYER_TO_PROBE\n)\n\nprint(f\"\\nThe probe can distinguish {POSITIVE_DIGITS} from {NEGATIVE_DIGITS}\")\nprint(f\"at layer {LAYER_TO_PROBE} with {accuracy:.1%} accuracy!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize what the probe learned (which neurons it relies on)\nvisualize_probe_weights(probe, title=f\"Probe Weights for Layer {LAYER_TO_PROBE}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# EXPERIMENT 2: Compare probe accuracy across all layers\n# =============================================================================\n# This shows at which layer the concept becomes most detectable\n\nresults = compare_probes_across_layers(\n    model, train_loader, test_loader,\n    positive_digits=POSITIVE_DIGITS,\n    negative_digits=NEGATIVE_DIGITS\n)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Try Your Own Experiments!\n\nModify the cells below to test different hypotheses about what the network has learned.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# EXPERIMENT 3: Even vs Odd digits\n# =============================================================================\n# Try probing for even vs odd - does the network represent this concept?\n\nEVEN_DIGITS = [0, 2, 4, 6, 8]\nODD_DIGITS = [1, 3, 5, 7, 9]\n\nprobe_even_odd, acc_even_odd = train_probe(\n    model, train_loader, test_loader,\n    positive_digits=EVEN_DIGITS,\n    negative_digits=ODD_DIGITS,\n    layer_num=2  # Try different layers!\n)\n\nprint(f\"\\nEven vs Odd probe accuracy: {acc_even_odd:.1%}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# EXPERIMENT 4: Single digit pair\n# =============================================================================\n# How well can the network distinguish between two specific digits?\n\nDIGIT_A = [3]  # Change this!\nDIGIT_B = [8]  # Change this!\n\nprobe_pair, acc_pair = train_probe(\n    model, train_loader, test_loader,\n    positive_digits=DIGIT_A,\n    negative_digits=DIGIT_B,\n    layer_num=2\n)\n\nprint(f\"\\n{DIGIT_A} vs {DIGIT_B} probe accuracy: {acc_pair:.1%}\")\nvisualize_probe_weights(probe_pair, title=f\"Probe for {DIGIT_A} vs {DIGIT_B}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# EXPERIMENT 5: Your own hypothesis!\n# =============================================================================\n# What other concepts might the network have learned?\n# Ideas:\n#   - Digits > 5 vs <= 5\n#   - Digits with curves (0,2,3,5,6,8,9) vs straight lines (1,4,7)\n#   - Digits with horizontal lines (2,4,5,7) vs without\n#\n# Fill in your own groups below:\n\nMY_POSITIVE_DIGITS = []  # Fill this in!\nMY_NEGATIVE_DIGITS = []  # Fill this in!\n\n# Uncomment when ready:\n# probe_custom, acc_custom = train_probe(\n#     model, train_loader, test_loader,\n#     positive_digits=MY_POSITIVE_DIGITS,\n#     negative_digits=MY_NEGATIVE_DIGITS,\n#     layer_num=2\n# )\n# print(f\"Custom probe accuracy: {acc_custom:.1%}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}